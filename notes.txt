What is Tools?
- It is just a Python function (or API) that is packaged in a way the LLM can understand and call when needed.

LLMs(like GPT) are great at:
- Reasoning
- Language Generation

But they can't do things like:
- Access live data (weather, news)
- Do reliable math
- Call APIs
- Run Code
- Interact with a database

Types of Tools:
A. Built-in Tools
B. Custom Tools

How Tools fits into the Agent ecosystem:
- An AI agent is a LLM-powered system that can automatically think,decide, and take actions using external tools or APIs to achieve a goal.

Reasoning & Decision Making: LLM + Action: Tools = AI Agent

A. Built-in Tools:
- It is a tool that Langchain already provides for you-it's pre-built, production ready, and requires minimal or no setup.
- You donot have to write the function logic yourself - you just import and use it.

Example:
- DuckDuckGoSearchRun: Web Search via DuckDuckGo
- WikipediaQueryRun: Wikipedia Summary
- PythonREPLTool: Run Raw Python Code
- ShellTool: Run Shell Commands
- RequestsGetTool: Make HTTP Requests
- GmailSendMessageTool: Send emails via Gmail
- SlackSendMessageTool: Post messages to Slack
- SQLDatabaseQueryTool: Run SQL Queries

B. Custom Tools:
- It is a tool that you define yourself.
- Use them When:
   .You want to call your own APIs.
   .You want to encapsulate business logic.
   .You want the LLM to interact with your database, product or app.
-Ways to create Custom Tools:
   .Using @tool decorator
   .Using StructuredTool & Pydantic
   .Using BaseTool class
- StructuredTool:
  It is a tool in Langchain is a special type of tool where the input to the tool follows a structured schema, typically defined using a Pydantic model.

- BaseTool:
  It is the abstract base class for all tools in Langchain. It defines the core structure and interface that any tool must follow, whether it's a simple one-linear or a fully customized function.

  All other tool types like @tool, StructuredTool are built on top of BaseTool.

Toolkits:
- It is just a collection (bundle) of related tools that serve a common purpose packaged together for convenience and reusability.

In LangChain:
- A toolkit might be: GoogleDriveToolKit.
- And it can contain the following tools:
  GoogleDriveCreateFileTool: Upload a file
  GoogleDriveSearchTool: Search for a file by name/content
  GoogleDriveReadFileTool: Read contents of a file


A) Tool Binding:
- It is the step where you register tools with a Language Model(LLM) so that:
   . The LLM knows what tools are available.
   . It knows what each tool does(via description).
   . It knows what input format to use(via schema).

B) Tool Calling:
- It is the process where the LLM decides, during a conversation ar task, that it needs to use a specific tool(function)- and generates a structured output with:
  . the name of the tool
  . and the arguments to call it with

- The LLM doesn't actually run the tool - it just suggests the tool and the input arguments. The actual execution is handled by LangChain or you.

- Example:
  "What's 8 multiply by 7?"

  The LLM responds with a tool call:
  json:
  ```
  {
    "tool": "multiply",
    "args": {"a":8,"b":7}
  }
  ```

C) Tool Execution:
- It is the step where the actual Python function(tool) is run using the input arguments that the LLM suggested during tool calling.

In Simple Words:
  The LLM says:
   "Hey, Call the multiply tool with a=8 and b=89."
   Tool Execution is when you or LangChain actually run:
   multiply(a=8,b=7)
   - And get the result back: 56

- This is not exactly work as like the AI Agent works:

1. User says: "Convert 10 USD to INR".
2. LLM think: "I don't know the rate. First, let me call get_conversion_factor.
3. Tool result comes: 85.3415.
4. LLM looks at result Thinks again: "Now I know the rate, next i should call convert with 10 and 85.3415."
5. Tool result comes: 853.415.
6. LLM summarizes: "10 USD is 853.415 INR at current rate."